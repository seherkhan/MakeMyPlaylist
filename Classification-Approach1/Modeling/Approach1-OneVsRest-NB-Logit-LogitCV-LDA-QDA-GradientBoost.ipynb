{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# data used contains duplicates, i.e. multilabelling problem\n",
    "datafile='/home/seherkhan/myfiles/coursework/usc/fall2018/MLforDI/project/FinalDraft/data/playlist_data_21oct_withdups.csv'\n",
    "df=pd.read_csv(datafile,sep='|')\n",
    "#print df\n",
    "#print len(df)\n",
    "tmp_X = df.iloc[:,4:18]\n",
    "tmp_y = df.iloc[:,18:19]\n",
    "tmp_y['playlist'] = tmp_y['playlist'].astype('category')\n",
    "tmp_y['playlist_codes']=tmp_y['playlist'].cat.codes\n",
    "scaler = StandardScaler()\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X=scaler.fit_transform(tmp_X)\n",
    "y=np.ravel(tmp_y['playlist_codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "accuracy = 0.37799512915762734\n",
      "prediction = 0.37799512915762734\n",
      "recall = 0.37799512915762734\n",
      "f_score = 0.37799512915762734\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "accuracy = 0\n",
    "prediction = 0 \n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    X_1,X_2=X[train_index],X[test_index]\n",
    "    y_1,y_2=y[train_index],y[test_index]\n",
    "\n",
    "X_train = X_1\n",
    "X_test = X_2\n",
    "y_train = y_1\n",
    "y_test = y_2\n",
    "\n",
    "print 'Gaussian Naive Bayes'\n",
    "gnb = GaussianNB()\n",
    "clf = OneVsRestClassifier(gnb)\n",
    "\n",
    "for n in range(5):\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        X_1,X_2=X[train_index],X[test_index]\n",
    "        y_1,y_2=y[train_index],y[test_index]\n",
    "        \n",
    "    X_train = X_1\n",
    "    X_test = X_2\n",
    "    y_train = y_1\n",
    "    y_test = y_2\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "    X_train = X_2\n",
    "    X_test = X_1\n",
    "    y_train = y_2\n",
    "    y_test = y_1\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "# calculate average accuracy\n",
    "    \n",
    "accuracy = accuracy/10\n",
    "prediction = prediction/10 \n",
    "recall = recall/10\n",
    "f_score = f_score/10\n",
    "\n",
    "print 'accuracy =', accuracy\n",
    "print 'prediction =', prediction\n",
    "print 'recall =', recall\n",
    "print 'f_score =', f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis\n",
      "accuracy = 0.40296577580909804\n",
      "prediction = 0.40296577580909804\n",
      "recall = 0.40296577580909804\n",
      "f_score = 0.40296577580909804\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "accuracy = 0\n",
    "prediction = 0 \n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    X_1,X_2=X[train_index],X[test_index]\n",
    "    y_1,y_2=y[train_index],y[test_index]\n",
    "\n",
    "X_train = X_1\n",
    "X_test = X_2\n",
    "y_train = y_1\n",
    "y_test = y_2\n",
    "\n",
    "print 'Linear Discriminant Analysis'\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "clf = OneVsRestClassifier(lda)\n",
    "\n",
    "for n in range(5):\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        X_1,X_2=X[train_index],X[test_index]\n",
    "        y_1,y_2=y[train_index],y[test_index]\n",
    "        \n",
    "    X_train = X_1\n",
    "    X_test = X_2\n",
    "    y_train = y_1\n",
    "    y_test = y_2\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "    X_train = X_2\n",
    "    X_test = X_1\n",
    "    y_train = y_2\n",
    "    y_test = y_1\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "# calculate average accuracy\n",
    "    \n",
    "accuracy = accuracy/10\n",
    "prediction = prediction/10 \n",
    "recall = recall/10\n",
    "f_score = f_score/10\n",
    "\n",
    "print 'accuracy =', accuracy\n",
    "print 'prediction =', prediction\n",
    "print 'recall =', recall\n",
    "print 'f_score =', f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Discriminant Analysis\n",
      "accuracy = 0.389284737609231\n",
      "prediction = 0.389284737609231\n",
      "recall = 0.389284737609231\n",
      "f_score = 0.389284737609231\n"
     ]
    }
   ],
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "\n",
    "accuracy = 0\n",
    "prediction = 0 \n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    X_1,X_2=X[train_index],X[test_index]\n",
    "    y_1,y_2=y[train_index],y[test_index]\n",
    "\n",
    "X_train = X_1\n",
    "X_test = X_2\n",
    "y_train = y_1\n",
    "y_test = y_2\n",
    "\n",
    "print 'Quadratic Discriminant Analysis'\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "clf = OneVsRestClassifier(qda)\n",
    "\n",
    "for n in range(5):\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        X_1,X_2=X[train_index],X[test_index]\n",
    "        y_1,y_2=y[train_index],y[test_index]\n",
    "        \n",
    "    X_train = X_1\n",
    "    X_test = X_2\n",
    "    y_train = y_1\n",
    "    y_test = y_2\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "    X_train = X_2\n",
    "    X_test = X_1\n",
    "    y_train = y_2\n",
    "    y_test = y_1\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "# calculate average accuracy\n",
    "    \n",
    "accuracy = accuracy/10\n",
    "prediction = prediction/10 \n",
    "recall = recall/10\n",
    "f_score = f_score/10\n",
    "\n",
    "print 'accuracy =', accuracy\n",
    "print 'prediction =', prediction\n",
    "print 'recall =', recall\n",
    "print 'f_score =', f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seherkhan/.local/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.4275954731406732\n",
      "prediction = 0.4275954731406732\n",
      "recall = 0.4275954731406732\n",
      "f_score = 0.4275954731406732\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "accuracy = 0\n",
    "prediction = 0 \n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    X_1,X_2=X[train_index],X[test_index]\n",
    "    y_1,y_2=y[train_index],y[test_index]\n",
    "\n",
    "X_train = X_1\n",
    "X_test = X_2\n",
    "y_train = y_1\n",
    "y_test = y_2\n",
    "\n",
    "print 'Logistic Regression'\n",
    "logit = LogisticRegression()\n",
    "clf = OneVsRestClassifier(logit)\n",
    "\n",
    "for n in range(5):\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        X_1,X_2=X[train_index],X[test_index]\n",
    "        y_1,y_2=y[train_index],y[test_index]\n",
    "        \n",
    "    X_train = X_1\n",
    "    X_test = X_2\n",
    "    y_train = y_1\n",
    "    y_test = y_2\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "    X_train = X_2\n",
    "    X_test = X_1\n",
    "    y_train = y_2\n",
    "    y_test = y_1\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "# calculate average accuracy\n",
    "    \n",
    "accuracy = accuracy/10\n",
    "prediction = prediction/10 \n",
    "recall = recall/10\n",
    "f_score = f_score/10\n",
    "\n",
    "print 'accuracy =', accuracy\n",
    "print 'prediction =', prediction\n",
    "print 'recall =', recall\n",
    "print 'f_score =', f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seherkhan/.local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.3141545502513314\n",
      "prediction = 0.3141545502513314\n",
      "recall = 0.3141545502513314\n",
      "f_score = 0.3141545502513314\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression CV\n",
    "\n",
    "accuracy = 0\n",
    "prediction = 0 \n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    X_1,X_2=X[train_index],X[test_index]\n",
    "    y_1,y_2=y[train_index],y[test_index]\n",
    "\n",
    "X_train = X_1\n",
    "X_test = X_2\n",
    "y_train = y_1\n",
    "y_test = y_2\n",
    "\n",
    "print 'Logistic Regression CV'\n",
    "logitcv = LogisticRegressionCV()\n",
    "clf = OneVsRestClassifier(logitcv)\n",
    "\n",
    "for n in range(5):\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        X_1,X_2=X[train_index],X[test_index]\n",
    "        y_1,y_2=y[train_index],y[test_index]\n",
    "        \n",
    "    X_train = X_1\n",
    "    X_test = X_2\n",
    "    y_train = y_1\n",
    "    y_test = y_2\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "    X_train = X_2\n",
    "    X_test = X_1\n",
    "    y_train = y_2\n",
    "    y_test = y_1\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "# calculate average accuracy\n",
    "    \n",
    "accuracy = accuracy/10\n",
    "prediction = prediction/10 \n",
    "recall = recall/10\n",
    "f_score = f_score/10\n",
    "\n",
    "print 'accuracy =', accuracy\n",
    "print 'prediction =', prediction\n",
    "print 'recall =', recall\n",
    "print 'f_score =', f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "accuracy = 0.48483583876976377\n",
      "prediction = 0.48483583876976377\n",
      "recall = 0.48483583876976377\n",
      "f_score = 0.48483583876976377\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost CV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "accuracy = 0\n",
    "prediction = 0 \n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    X_1,X_2=X[train_index],X[test_index]\n",
    "    y_1,y_2=y[train_index],y[test_index]\n",
    "\n",
    "X_train = X_1\n",
    "X_test = X_2\n",
    "y_train = y_1\n",
    "y_test = y_2\n",
    "\n",
    "print 'GradientBoost'\n",
    "gb = GradientBoostingClassifier()\n",
    "clf = OneVsRestClassifier(gb)\n",
    "\n",
    "for n in range(5):\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        X_1,X_2=X[train_index],X[test_index]\n",
    "        y_1,y_2=y[train_index],y[test_index]\n",
    "        \n",
    "    X_train = X_1\n",
    "    X_test = X_2\n",
    "    y_train = y_1\n",
    "    y_test = y_2\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "    X_train = X_2\n",
    "    X_test = X_1\n",
    "    y_train = y_2\n",
    "    y_test = y_1\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = precision_recall_fscore_support(y_test, pred, labels=range(14), average='micro')\n",
    "    accuracy = accuracy + accuracy_score(y_test, pred, normalize=True)\n",
    "    prediction = prediction + score[0]\n",
    "    recall = recall + score[1]\n",
    "    f_score = f_score + score[2]\n",
    "    \n",
    "# calculate average accuracy\n",
    "    \n",
    "accuracy = accuracy/10\n",
    "prediction = prediction/10 \n",
    "recall = recall/10\n",
    "f_score = f_score/10\n",
    "\n",
    "print 'accuracy =', accuracy\n",
    "print 'prediction =', prediction\n",
    "print 'recall =', recall\n",
    "print 'f_score =', f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
